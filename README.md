# ğŸŒ± EcoPrompt AI â€“ Sustainable Prompt Engineering for Energy Efficiency

## Group #8
* Eris Leksi (9067882)
* Erica Holden (5490685)
* Reham Abuarquob (9062922)
 

## Everything from the presentation is explained down here:

## ğŸ“Œ Overview
This project focuses on **optimizing AI prompts** to reduce **energy consumption** while maintaining semantic accuracy and output quality.  
It leverages **Natural Language Processing (NLP)** models like **T5** and **Sentence-BERT (SBERT)** to:
- Shorten and improve prompts.
- Predict energy usage differences.
- Estimate potential **cost savings**.
- Assess semantic similarity between original and optimized prompts.

The system is implemented as a **Streamlit web application** following the **MVC architecture**, with backend prediction, API integration, and database support.

## ğŸ›‘ Our Problem
AI models are becoming increasingly energy-intensive, creating both **environmental challenges** and **regulatory pressures**.  
Our project addresses the urgent need to **measure, report, and optimize** AI energy usage.

**Key Challenges:**
- âš  **1,240 AI data centers** projected to be built in 2025.
- ğŸ’§ **Severe water usage**, especially in dry regions.
- ğŸ’¡ **EU regulation (2026):** Mandatory AI energy reporting.
- ğŸ’° **$9.2B** in health-related costs from AI emissions.

**Our Goal:**  
Enable **transparent, efficient AI usage** with smart prompt/context engineering and real-time energy insights.


## ğŸ’¼ Business Implementation

This project is designed to integrate seamlessly into real-world AI workflows, enabling organizations to **optimize prompts**, **reduce energy usage**, and **maintain high-quality outputs**.

**Workflow:**
1. **User Interaction** â€“ A user submits a request through an application or interface.
2. **Prompt Generation** â€“ Initial prompts are created for AI processing.
3. **Prompt Optimization** â€“ Our system refines prompts using smart engineering to reduce token count while preserving meaning.
4. **Energy & Cost Tracking** â€“ Energy usage is monitored and estimated in real-time.
5. **AI Execution** â€“ The optimized prompt is processed through large models such as **ChatGPT**, **Gemini**, or **Copilot**.
6. **Insights & Reporting** â€“ Energy savings, semantic similarity, and performance metrics are shared with stakeholders for transparency.
7. **Business Integration** â€“ Results are used to improve efficiency in operations, marketing, customer service, and more.


## ğŸŒ Relevance

### **Social & Economic**
- Make chatbots and virtual assistants **more affordable and sustainable**.
- Reduce the **carbon footprint** of messaging and search.
- Improve **accessibility** of NLPs in regions with limited computing resources.
- Promote **sustainable computing** in alignment with global climate goals.

### **Industrial**
- Reduce **compute time** on platforms like AWS, Azure, GCP, lowering operational costs.
- Prepare industries for **upcoming environmental regulations** on AI energy usage and carbon tracking.
- Enable **more queries per second** on existing infrastructure without extra hardware.
- Lower server workload, reducing cooling demands and **extending hardware lifespan**.


## ğŸš€ Features
- **Prompt Optimization**: Generates a longer yet more energy efficient prompt than the input one.
- **Energy Prediction**: Estimates energy consumption before and after optimization.
- **Cost Savings Calculation**: Converts energy savings into $ savings based on Province of Ontario average electricity rate.
- **Semantic Similarity**: Measures closeness between original and optimized prompts using SBERT cosine similarity.
- **Transparency Metrics**: Displays shortening coefficient, output confidence, energy savings %, $ savings.
- **Interactive Web App**: Built with **Streamlit** for quick deployment and user interaction.


## ğŸ’¡ Why This Project Matters

AI models consume significant energy, leading to high costs and environmental impact.  
This project reduces that footprint by **optimizing prompts** to lower computation while preserving meaning, tracking energy use, and promoting **sustainable, cost-efficient AI**.


## ğŸ“Š Dataset
We use the [LLM Inference Energy Consumption Dataset](https://huggingface.co/datasets/ejhusom/llm-inference-energy-consumption) containing:
- Prompt text & characteristics.
- Token counts.
- Model parameters & inference settings.
- Measured energy usage.
- etc


## ğŸ— Architecture
**Workflow**:
1. **Preprocessing** â€“ Tokenization, cleaning, and feature extraction from prompts.
2. **Model Training**:
   - **BERT/SBERT** for semantic similarity.
   - **T5** for prompt rewriting.
   - Regression models (Linear, Polynomial, Tree-based) for energy & cost prediction.
3. **Prediction Pipeline** â€“ Given a new prompt, output:
   - Optimized prompt
   - Energy usage (old vs. new)
   - $ savings
   - Similarity score
4. **Frontend** â€“ Streamlit app for visualization & interaction.
5. **Persistence** â€“ Models saved using `joblib` in the `/models` directory.


## ğŸ— Architecture Diagram

The system is designed with a modular architecture to allow **scalable AI energy optimization**:

1. **User Interaction** â€“ Users submit prompts via the Streamlit web application.
2. **API Server** â€“  
   - Endpoints:  
     - `/predict` â€“ Main prediction route.  
     - `/predict_by_verbs` â€“ Prediction based on instruction complexity.  
   - Controller â€“ Routes requests to the correct processing service.  
   - Predictor Service â€“ Handles preprocessing, optimization, and model calls.
3. **ML Models** â€“  
   - **BART Class** â€“ Performs prompt rephrasing for optimization.  
   - **SBERT Class** â€“ Computes semantic similarity between original and optimized prompts.  
   - **Exponential Offset Model** â€“ Predicts energy savings based on prompt features.


## ğŸ”„ NLP Pipeline

Our system follows a structured **NLP pipelining process** to transform raw text into optimized prompts with measurable energy savings:

1. **Text Acquisition** â€“ Ingest raw text from sources and capture metadata.  
2. **Text Preprocessing / Cleaning** â€“ Lowercasing, trimming whitespace, and Unicode normalization.  
3. **Tokenization & Linguistic Analysis** â€“ Segment and annotate text.  
4. **Vectorization** â€“ Generate contextual embeddings for meaning-aware models.  
5. **Feature Engineering** â€“ Compute readability and sentiment scores.  
6. **Modeling** â€“ Apply **BART** for rephrasing, **Random Forest** for energy prediction, and **SBERT** for semantic similarity.  
7. **Evaluation** â€“ Measure energy saved (%), cost saved, similarity, and confidence.  
8. **Deployment** â€“ FastAPI backend with a Streamlit frontend.


## ğŸ“‚ Project Structure
CSCN8010_FinalProject_EnergyEstimator
|  Documents/
â”‚ â””â”€â”€ GDC.png # Project diagram or related image
â”‚
â”œâ”€â”€ api/ # API-related code
â”‚ â”œâ”€â”€ controllers/ # Controllers handle incoming API requests
â”‚ â”‚ â””â”€â”€ predict_controller.py # Logic for prediction API endpoints
â”‚ â”œâ”€â”€ models/ # Data models for API requests/responses
â”‚ â”‚ â””â”€â”€ predict_request.py # Request model for prediction inputs
â”‚ â””â”€â”€ services/ # Backend service logic
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ main.py # Entry point for service execution
â”‚ â””â”€â”€ requirements.txt # Dependencies for the service module
â”‚
â”œâ”€â”€ data/ # Dataset files
â”‚ â”œâ”€â”€ alpaca_llama3_70b_server.csv # Model output dataset
â”‚ â””â”€â”€ improved_prompts.csv # Optimized prompts dataset
â”‚
â”œâ”€â”€ models/ # Saved ML models
â”‚ â”œâ”€â”€ sbert_model/ # SBERT model directory
â”‚ â”‚ â”œâ”€â”€ 1_Pooling/ # Pooling configuration
â”‚ â”‚ â”‚ â”œâ”€â”€ config.json
â”‚ â”‚ â”‚ â””â”€â”€ README.md
â”‚ â”‚ â”œâ”€â”€ config.json
â”‚ â”‚ â”œâ”€â”€ config_sentence_transformers.json
â”‚ â”‚ â”œâ”€â”€ model.safetensors
â”‚ â”‚ â”œâ”€â”€ modules.json
â”‚ â”‚ â”œâ”€â”€ sentence_bert_config.json
â”‚ â”‚ â”œâ”€â”€ special_tokens_map.json
â”‚ â”‚ â”œâ”€â”€ tokenizer.json
â”‚ â”‚ â”œâ”€â”€ tokenizer_config.json
â”‚ â”‚ â”œâ”€â”€ vocab.txt
â”‚ â”‚ â”œâ”€â”€ init.py
â”‚ â”‚ â”œâ”€â”€ bart_model.pkl # Trained BART model
â”‚ â”‚ â”œâ”€â”€ energy_model_rf.pkl # Random Forest model for energy prediction
â”‚ â”‚ â”œâ”€â”€ exp_offset_model.pkl # Exponential offset model
â”‚ â”‚ â””â”€â”€ sbert_model.pkl # Trained SBERT model
â”‚
â”œâ”€â”€ notebooks/ # Jupyter Notebooks for experiments
â”‚ â”œâ”€â”€ NLP_script.ipynb # NLP processing and training
â”‚ â””â”€â”€ prediction_script.ipynb # Prediction testing and evaluation
â”‚
â”œâ”€â”€ scripts/ # Utility or helper scripts
â”‚
â”œâ”€â”€ .gitattributes
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md # Project documentation
â”œâ”€â”€ app.py # Main application script
â”œâ”€â”€ exp_offset_model.py # Exponential offset model implementation
â”œâ”€â”€ integration.py # Integration logic for components
â””â”€â”€ requirements.txt # Project dependencies


## ğŸ“‚ Project Structure â€“ Explanation

- **Documents/** â€“ Contains supporting documentation or visuals for the project (e.g., diagrams, images).
  - `GDC.png` â€“ Graphic or diagram used in reports/presentations.

- **api/** â€“ API layer for serving predictions and handling requests.
  - **controllers/** â€“ Functions that process incoming HTTP requests and call the appropriate services.
    - `predict_controller.py` â€“ Handles prediction-related API endpoints.
  - **models/** â€“ Defines data structures for requests/responses.
    - `predict_request.py` â€“ Schema for input data to the prediction API.
  - **services/** â€“ Core business logic for processing predictions.
    - `main.py` â€“ API entry point.
    - `__init__.py` â€“ Marks the folder as a Python package.
    - `requirements.txt` â€“ Python dependencies specific to the API service.

- **data/** â€“ Raw and processed datasets used for training/testing.
  - `alpaca_llama3_70b_server.csv` â€“ Dataset with baseline prompts.
  - `improved_prompts.csv` â€“ Dataset with optimized prompts.

- **models/** â€“ Stored machine learning models and configurations.
  - **sbert_model/** â€“ Saved Sentence-BERT model and configuration files.
    - **1_Pooling/** â€“ Pooling layer configuration.
    - Various `.json` and `.txt` â€“ Model settings, tokenizer, and vocab.
    - `.pkl` files â€“ Serialized trained models:
      - `bart_model.pkl` â€“ BART model for prompt rephrasing.
      - `energy_model_rf.pkl` â€“ Random Forest model for energy prediction.
      - `exp_offset_model.pkl` â€“ Exponential offset model for energy estimation.
      - `sbert_model.pkl` â€“ SBERT model for semantic similarity.
  
- **notebooks/** â€“ Jupyter notebooks for experiments and analysis.
  - `NLP_script.ipynb` â€“ NLP preprocessing and training pipeline.
  - `prediction_script.ipynb` â€“ Testing predictions and model performance.

- **scripts/** â€“ Additional helper or automation scripts.

- **app.py** â€“ Main application script, possibly running the Streamlit frontend.
- **exp_offset_model.py** â€“ Implementation of the exponential offset energy model.
- **integration.py** â€“ Code integrating multiple components (models, API, frontend).
- **requirements.txt** â€“ Master list of Python dependencies.
- **.gitattributes / .gitignore** â€“ Git configuration files.
- **README.md** â€“ Project documentation.

## ğŸ“¦ Installation
```bash
# Clone the repository
git clone https://github.com/your-username/sustainable-ai.git
cd sustainable-ai

# Create and activate a virtual environment
python -m venv venv
source venv/bin/activate  # On Mac/Linux
venv\Scripts\activate     # On Windows

# Install dependencies
pip install -r requirements.txt
